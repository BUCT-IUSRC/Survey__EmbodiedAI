# **Paper list for Embodied AI**
#### We appreciate any useful suggestions for improvement of this paper list or survey from peers. Please raise issues or send an email to xxx. Thanks for your cooperation!
## üè† About
Embodied intelligence aims to create intelligent entities that can learn and evolve autonomously based on the interaction between machines and the physical world, by emphasizing the interaction among the brain, body, and
environment. Currently, the rapid development of multidisciplinary technologies such as machine learning, robotics, and cognitive science has greatly promoted the research and application of embodied intelligence. Existing literature mainly focuses on technical and methodological classifications of embodied intelligence. From a new perspective, this paper
starts from the key problems involved in the research and application of embodied intelligence. By analyzing the general framework of embodied intelligence research, specific research ideas are proposed for the two kernel stages including embodied perception and execution, as well as embodied learning and evolution. Accordingly, detailed explanations of relevant technologies and research progress related to these key issues are provided. In addition, typical applications in mobile robots, bionic robots, and parallel robotics are exploited to illustrate how embodied intelligence inspires practical
robot systems in terms of perception and understanding, control and decision-making, interaction and learning. Finally, the prospects of embodied intelligence is discussed, considering the importance and potential of virtual-real fusion data intelligence, foundation intelligence, and parallel intelligence. This paper is expected to provide new inspiration and ideas for scholars and practitioners in related fields.

## üìö Table of Contents

- [Surveys & Perspectives](#surveys--perspectives)
- [ÂÖ∑Ë∫´ÊÑüÁü•‰∏éÊâßË°å](#ÂÖ∑Ë∫´ÊÑüÁü•‰∏éÊâßË°å)  
&emsp;[ÁéØÂ¢É‰∏é‰ªªÂä°ÊÑüÁü•](#ÁéØÂ¢É‰∏é‰ªªÂä°ÊÑüÁü•)  
&emsp;[Ë°å‰∏∫ËßÑÂàí‰∏éÊéßÂà∂](#Ë°å‰∏∫ËßÑÂàí‰∏éÊéßÂà∂)  
&emsp;[ÂÖ∑Ë∫´Ê®°Êãü‰∏éAIGC](#ÂÖ∑Ë∫´Ê®°Êãü‰∏éAIGC)   
- [ÂÖ∑Ë∫´Â≠¶‰π†‰∏éËøõÂåñ](#ÂÖ∑Ë∫´Â≠¶‰π†‰∏éËøõÂåñ-)  
&emsp;[Âü∫Á°ÄÊ®°Âûã](#Âü∫Á°ÄÊ®°Âûã)  
&emsp;[Â¢ûÈáèÂ≠¶‰π†](#Â¢ûÈáèÂ≠¶‰π†)  
&emsp;[Âº∫ÂåñÂ≠¶‰π†](#Âº∫ÂåñÂ≠¶‰π†)      
- [Â§öÊô∫ËÉΩ‰ΩìÂçèÂêå](#Â§öÊô∫ËÉΩ‰ΩìÂçèÂêå-)
- [ÂÖ∑Ë∫´Êô∫ËÉΩÁ≥ªÁªü](#ÂÖ∑Ë∫´Êô∫ËÉΩÁ≥ªÁªü-)  
&emsp;[ÁßªÂä®Êú∫Âô®‰∫∫](#ÁßªÂä®Êú∫Âô®‰∫∫)  
&emsp;[‰ªøÁîüÊú∫Âô®‰∫∫](#‰ªøÁîüÊú∫Âô®‰∫∫)  
&emsp;[Âπ≥Ë°åÊú∫Âô®‰∫∫](#Âπ≥Ë°åÊú∫Âô®‰∫∫)  
&emsp;[ÁâπÁßçÊú∫Âô®‰∫∫](#ÁâπÁßçÊú∫Âô®‰∫∫)  
## Surveys & Perspectives[üîù](#-table-of-contents)

- [2]**Embodied intelligence weaves a better future**. Nature Machine Intelligence, 2020, 2(11): 663-664.Jin D, Zhang L.[[page]](https://www.nature.com/articles/s42256-020-00250-6)
- [5]**Evolving embodied intelligence from materials to machines**. Nature Machine Intelligence, 2019, 1(1): 12-19.Howard D, Eiben A E, Kennedy D F, et al. [[page]](https://www.nature.com/articles/s42256-018-0009-9)
- [6]**The journey/DAO/TAO of embodied intelligence: From large models to foundation intelligence and parallel intelligence**. IEEE/CAA Journal of Automatica Sinica, 2024, 11(6): 1313-1316.[[page]](https://ieeexplore.ieee.org/abstract/document/10539310/)
- [7]**Embodied intelligent driving: Concepts, methods, the state of the art and beyond**. Chinese Journal of Intelligent Science and Technology, 2024, 6(1): 17-32.Shen Tian-Yu, Li Zhi-Wei, Fan Li-Li, Zhang Ting-Zhen, Tang Dan-Dan, Zhou Mei-Hua, Liu Hua-Ping, Wang Kun-Feng.[[page]](https://www.infocomm-journal.com/znkx/EN/10.11959/j.issn.2096-6652.202404)
- [10]**Improving performance of robots using human-inspired approaches: A survey**. Science China Information Sciences, 2022, 65(12): 221201.Qiao H, Zhong S, Chen Z, et al.[[page]](https://link.springer.com/article/10.1007/s11432-022-3606-1)
- [11]**AI robots and humanoid AI: Review, perspectives and directions**. 2024.Cao L.[[page]](https://datasciences.org/publication/Humanoid-AI.pdf)
- [12]**A survey of embodied AI: From simulators to research tasks.** IEEE Transactions on Emerging Topics in Computational Intelligence, 2022, 6(2): 230-244.Duan J, Yu S, Tan H L, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/9687596/)
- [13]**Âü∫‰∫éÂΩ¢ÊÄÅÁöÑÂÖ∑Ë∫´Êô∫ËÉΩÁ†îÁ©∂: ÂéÜÂè≤ÂõûÈ°æ‰∏éÂâçÊ≤øËøõÂ±ï**. Ëá™Âä®ÂåñÂ≠¶Êä•, 2023, 49(6):1131‚àí1154.ÂàòÂçéÂπ≥, ÈÉ≠Ëø™, Â≠ôÂØåÊò•, Âº†Êñ∞Èí∞. [[page]](http://www.aas.net.cn/cn/article/doi/10.16383/j.aas.c220564?viewType=HTML&utm_source=TrendMD&utm_medium=cpc&utm_campaign=Acta_Automatica_Sinica_TrendMD_0)
- [69]**Evolutionary robotics: the Sussex approach**. Robotics and Autonomous Systems, 1997, 20(2-4): 205-224.Harvey I, Husbands P, Cliff D, et al.[[page]](https://www.sciencedirect.com/science/article/pii/S092188909600067X)
## ÂÖ∑Ë∫´ÊÑüÁü•‰∏éÊâßË°å[üîù](#-table-of-contents)
### ÁéØÂ¢É‰∏é‰ªªÂä°ÊÑüÁü•

- [2]**Embodied intelligence weaves a better future**. Nature Machine Intelligence, 2020, 2(11): 663-664.Jin D, Zhang L.[[page]](https://www.nature.com/articles/s42256-020-00250-6)
- [18]**Planning-oriented autonomous driving**. In: Proceeding of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023: 17853-17862.Hu Y, Yang J, Chen L, et al.[[page]](http://openaccess.thecvf.com/content/CVPR2023/html/Hu_Planning-Oriented_Autonomous_Driving_CVPR_2023_paper.html)
- [19]**Multimodal virtual point 3D detection**. Advances in Neural Information Processing Systems, 2021, 34: 16494-16507.Yin T, Zhou X, Kr√§henb√ºhl P. [[page]](https://proceedings.neurips.cc/paper/2021/hash/895daa408f494ad58006c47a30f51c1f-Abstract.html)
- [20]**Sparse fuse dense:Towards high quality 3D detection with depth completion**[C]// Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022: 5418-5427.Wu X, Peng L, Yang H, et al.[[page]](http://openaccess.thecvf.com/content/CVPR2022/html/Wu_Sparse_Fuse_Dense_Towards_High_Quality_3D_Detection_With_Depth_CVPR_2022_paper.html)
- [21]**Virtual sparse convolution for multimodal 3D object detection[C]**// Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023: 21653-21662.Wu H, Wen C, Shi S, et al. [[page]](http://openaccess.thecvf.com/content/CVPR2023/html/Wu_Virtual_Sparse_Convolution_for_Multimodal_3D_Object_Detection_CVPR_2023_paper.html)
- [22]**Bevfusion: Multi-task multi-sensor fusion with unified bird‚Äôs-eye view representation**[C]// Proceedings of the IEEE International Conference on Robotics and Automation, 2023: 2774-2781.Liu Z, Tang H, Amini A, et al. [[page]](https://ieeexplore.ieee.org/abstract/document/10160968/)
- [23]**BEV-CFKT: A LiDAR-camera cross-modality-interaction fusion and knowledge transfer framework with transformer for bev 3D object detection**. Neurocomputing, 2024, 582: 127527.Wei M, Li J, Kang H, et al. [[page]](https://www.sciencedirect.com/science/article/pii/S0925231224002984)
- [24]**DeepFusion: A robust and modular 3D object detector for LiDARs, cameras and radars**[C]// Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, 2022: 560-567.Drews F, Feng D, Faion F, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/9981778/)
- [25]**AMMF: Attention-based multi-phase multi-task fusion for small contour object 3D detection**. IEEE Transactions on Intelligent Transportation Systems, 2022, 24(2): 1692-1701.Xie B, Yang Z, Yang L, et al. [[page]](https://ieeexplore.ieee.org/abstract/document/9989542/)
- [26]**Probabilistic 3D multi-modal, multi-object tracking for autonomous driving**. In: Proceeding of the IEEE International Conference on Robotics and Automation, 2021: 14227-14233.Chiu H, Li J, Ambru≈ü R, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/9561754/)
- [27]**ACF-Net: Asymmetric cascade fusion for 3D detection with LiDAR point clouds and images**. IEEE Transactions on Intelligent Vehicles (Early Access),2023, 1-12.Tian Y, Zhang X, Wang X, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/10363115/)
- [28]**FusionFormer: A multi-sensory fusion in bird‚Äôs-eye-view and temporal consistent transformer for 3D objection**. arXiv preprint arXiv:2309.05257, 2023.Hu C, Zheng H, Li K, et al.[[page]](https://arxiv.org/abs/2309.05257)
- [29]**Prototypical pseudo label denoising and target structure learning for domain adaptive semantic segmentation**. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, 12414-12424.Zhang P, Zhang B, Zhang T, et al. [[page]](http://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Prototypical_Pseudo_Label_Denoising_and_Target_Structure_Learning_for_Domain_CVPR_2021_paper.html)
- [30]**Dranet: Disentangling representation and adaptation networks for unsupervised cross-domain adaptation**. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, 15252-15261.Lee S, Cho S, Im S.[[page]](http://openaccess.thecvf.com/content/CVPR2021/html/Lee_DRANet_Disentangling_Representation_and_Adaptation_Networks_for_Unsupervised_Cross-Domain_Adaptation_CVPR_2021_paper.html)
- [31]**Unsupervised domain adaptation of object detectors: A survey**[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023.Oza P, Sindagi V A, Sharmini V V, Patel V M.[[page]](https://ieeexplore.ieee.org/abstract/document/10075484/)
- [32]**Domain-adversarial training of neural networks**[J]. Journal of Machine Learning Research, 2016, 17(59): 1-35.Ganin Y, Ustinova E, Ajakan H, et al.[[page]](https://www.jmlr.org/papers/v17/15-239.html)
- [33]**Exploring object relation in mean teacher for cross-domain detection**[C]//IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 11457-11466.Cai Q, Pan Y, Ngo C W, Tian X, et al.[[page]](http://openaccess.thecvf.com/content_CVPR_2019/html/Cai_Exploring_Object_Relation_in_Mean_Teacher_for_Cross-Domain_Detection_CVPR_2019_paper.html)
- [34]**Droid: Driver-centric risk object identification**. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023, 45(11): 13683-13698.Li C, Chan S H, Chen Y T.[[page]](https://ieeexplore.ieee.org/abstract/document/10177972/)
- [35]**A superposition assessment framework of multi-source traffic risks for mega-events using risk field model and time-series generative adversarial networks**. IEEE Transactions on Intelligent Transportation Systems, 2023, 24(11): 12736-12753.Cheng Z, Lu J, Ding H, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/10186236/)
- [36]**Probabilistic risk metric for highway driving leveraging multi-modal trajectory predictions**. IEEE Transactions on Intelligent Transportation Systems, 2022, 23(10): 19399-19412.Wang X, Alonso M J, Wang M.[[page]](https://ieeexplore.ieee.org/abstract/document/9751230/)
- [37]**A multivariate-based conflict prediction model for a brazilian freeway**. Accident Analysis & Prevention, 2017, 98: 295-302.Caleffi F, Anzanello M J, Cybis H B B.[[page]](https://www.sciencedirect.com/science/article/pii/S0001457516303864)
### Ë°å‰∏∫ËßÑÂàí‰∏éÊéßÂà∂

- [45]**A formal basis for the heuristic determination of minimum cost paths**. IEEE Transactions on Systems Science and Cybernetics, 1968, 4(2): 100-107.Hart P E, Nilsson N J, Raphael B.[[page]](https://ieeexplore.ieee.org/abstract/document/4082128/)
- [46]**Sampling-based algorithms for optimal motion planning**. The International Journal of Robotics Research, 2011, 30(7): 846-894.Karaman S, Frazzoli E. [[page]](https://journals.sagepub.com/doi/abs/10.1177/0278364911406761)
- [47]**D* lite**.In: Proceeding of the Eighteenth National Conference on Artificial IntelligenceÔºå2002: 476-483.Koenig S, Likhachev M.[[page]](https://dl.acm.org/doi/abs/10.5555/777092.777167)
- [48]**Adaptation in natural and artificial systems: An introductory analysis with applications to biology**, control, and artificial intelligence. MIT press, 1992.Holland J H.[[page]](https://books.google.com/books?hl=zh-CN&lr=&id=5EgGaBkwvWcC&oi=fnd&pg=PR7&dq=Adaptation+in+natural+and+artificial+systems:+An+introductory+analysis+with+applications+to+biology&ots=mKhl1YIqqq&sig=nd5MH9s5V3xDdJMm2WtJ7hqDxVs)
- [49]**Particle swarm optimization. In: Proceeding of the ICNN‚Äô95-International Conference on Neural Networks**, 1995: 1942-1948.Kennedy J, Eberhart R.[[page]](https://ieeexplore.ieee.org/abstract/document/488968/)
- [50]**Practical search techniques in path planning for autonomous driving**. Ann Arbor, 2008, 1001(48105): 18-80.Dolgov D, Thrun S, Montemerlo M, et al.[[page]](https://cdn.aaai.org/Workshops/2008/WS-08-10/WS08-10-006.pdf)
- [51]**Kinodynamic RRT*: Asymptotically optimal motion planning for robots with linear dynamics**. In: Proceeding of the 2013 IEEE international conference on robotics and automation, 2013: 5054-5061.Webb D J, Van Den Berg J.[[page]](https://ieeexplore.ieee.org/abstract/document/6631299/)
- [52]**On Actor-Critic Algorithms. **Society for Industrial and Applied Mathematics, 2003.Konda V R, Tsitsiklis J N.[[page]](https://proceedings.neurips.cc/paper/1999/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html)
- [53]**Technical Note: Q-Learning**, 1992.Watkins C J C H. P.[[page]](https://link.springer.com/article/10.1007/bf00992698)
- [54]**PILCO: A Model-based and data-efficient approach to policy search**.In: Proceeding of the 28th International Conference on Machine Learning, 2011.Deisenroth M P, Rasmussen C E.[[page]](http://aiweb.cs.washington.edu/research/projects/aiweb/media/papers/tmpZj4RyS.pdf)
- [55]**Generative adversarial lmitation learning**. 2016.Ho J, Ermon S.[[page]](https://proceedings.neurips.cc/paper_files/paper/2016/hash/cc7e2b878868cbae992d1fb743995d8f-Abstract.html)
- [56]**A review of PID control, tuning methods and applications**. International Journal of Dynamics and Control, 2021, 9: 818-827.Borase R P, Maghade D K, Sondkar S Y, et al.[[page]](https://link.springer.com/article/10.1007/s40435-020-00665-4)
- [57]**On the role of regularization in direct data-driven LQR control**. 2022 IEEE 61st Conference on Decision and Control (CDC). IEEE, 2022: 1091-1098.D√∂rfler F, Tesi P, De Persis C. [[page]](https://ieeexplore.ieee.org/abstract/document/9992770/)
- [58]**Robust data-driven state-feedback design**.** 2020 American Control Conference (ACC)**. IEEE, 2020: 1532-1538.Berberich J, Koch A, Scherer C W, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/9147320/)
- [59]**Safe and fast tracking on a robot manipulator: Robust mpc and neural network control**. IEEE Robotics and Automation Letters, 2020, 5(2): 3050- 3057.Nubert J, K√∂hler J, Berenz V, et al. [[page]](https://ieeexplore.ieee.org/abstract/document/9006856/)
- [60]**Adaptive neural network control for a class of nonlinear systems with function constraints on states**. IEEE Transactions on Neural Networks and Learning Systems, 2021, 34(6): 2732-2741.Liu Y J, Zhao W, Liu L, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/9537635/)
- [61]**Interval type 2 fuzzy logic control for energy management of hybrid electric autonomous vehicles**. IEEE Transactions on Intelligent Vehicles, 2020, 6(2): 210-220.Phan D, Bab-Hadiashar A, Fayyazi M, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/9149783/)
- [62]**Cooperative co-evolution with differential grouping for large scale optimization**. IEEE Transactions on Evolutionary Computation, 2013, 18(3): 378- 393.Omidvar M N, Li X, Mei Y, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/6595612/)
- [63]**Particle swarm optimization algorithm and its applications: a systematic review**. Archives of Computational Methods in Engineering, 2022, 29(5): 2531-2561.Gad A G. [[page]](https://link.springer.com/article/10.1007/S11831-021-09694-4)
- [64]**Distributed optimal control for multi-agent trajectory optimization**. Automatica, 2014, 50(1): 149-154.Foderaro G, Ferrari S, Wettergren T A. [[page]](https://www.sciencedirect.com/science/article/pii/S0005109813004470)
- [65]**A distributional perspective on reinforcement learning**. In: Proceeding of the International Conference on Machine Learning, 2017: 449-458.Bellemare M G, Dabney W, Munos R. [[page]](http://proceedings.mlr.press/v70/bellemare17a.html?trk=public_post_comment-text)
- [66]**Finite-time consensus tracking neural network FTC of multi-agent systems**. IEEE Transactions on Neural Networks and Learning Systems, 2020, 32(2): 653-662.Dong G, Li H, Ma H, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/9055378/)
- [67]**Leader-following consensus of multi-agent systems under antagonistic networks**. Neurocomputing. 2020 Nov 6;413:339-47.Wang Q, Liu K, Wang X, Wu L, L√º J.[[page]](https://www.sciencedirect.com/science/article/pii/S0925231220311127)
- [68]**Virtual target guidance-based distributed model predictive control for formation control of multiple UAVs**. Chinese Journal of Aeronautics, 2020, 33(3): 1037-1056.Zhihao C, Longhong W, Jiang Z, Kun W, Yingxun W.[[page]](https://www.sciencedirect.com/science/article/pii/S1000936119302833)
### ÂÖ∑Ë∫´Ê®°Êãü‰∏éAIGC

- [38]**High-resolution image synthesis with latent diffusion models**.Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 10684-10695.Rombach R, Blattmann A, Lorenz D, et al.[[page]](http://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html)
- [39]**Photorealistic text-to image diffusion models with deep language understanding**. Advances in neural information processing systems, 2022, 35: 36479-36494.Saharia C, Chan W, Saxena S, et al.[[page]](https://proceedings.neurips.cc/paper_files/paper/2022/hash/ec795aeadae0b7d230fa35cbaf04c041-Abstract-Conference.html)
- [40]**Zero-shot text-to image generation. International conference on machine learning**. Pmlr, 2021: 8821-8831.Ramesh A, Pavlov M, Goh G, et al.[[page]](https://proceedings.mlr.press/v139/ramesh21a.html?ref=journey)
- [41]**Hierarchical text-conditional image generation with clip latents**. arXiv preprint arXiv:2204.06125, 2022, 1(2): 3.Ramesh A, Dhariwal P, Nichol A, et al.[[page]](https://proceedings.mlr.press/v139/ramesh21a.html?ref=journey)
- [42]**A generalist agent**[J]. arXiv preprint arXiv:2205.06175, 2022.Reed S, Zolna K, Parisotto E, et al.[[page]](https://arxiv.org/abs/2205.06175)
- [43]**Giraffe: Representing scenes as compositional generative neural feature fields**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 11453-11464.Niemeyer M, Geiger A.[[page]](http://openaccess.thecvf.com/content/CVPR2021/html/Niemeyer_GIRAFFE_Representing_Scenes_As_Compositional_Generative_Neural_Feature_Fields_CVPR_2021_paper.html)
- [44]**Physically Embodied Gaussian Splatting: Embedding Physical Priors into a Visual 3D World Model For Robotics**, Conference on Robot Learning. 2023 (7th).Abou-Chakra J, Rana K, Dayoub F, et al.[[page]](https://eprints.qut.edu.au/247354/)
- [145]**Palm-e: An embodied multimodal language model**. arXiv preprint arXiv:2303.03378, 2023.Driess D, Xia F, Sajjadi M S M, et al.[[page]](https://arxiv.org/abs/2303.03378)
- [146]**Alfred: A benchmark for interpreting grounded instructions for everyday tasks**. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020: 10740-10749.Shridhar M, Thomason J, Gordon D, et al. [[page]](http://openaccess.thecvf.com/content_CVPR_2020/html/Shridhar_ALFRED_A_Benchmark_for_Interpreting_Grounded_Instructions_for_Everyday_Tasks_CVPR_2020_paper.html)
- [147]**Visual room rearrangement**. In: Proceeding of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021: 5922-5931.Weihs L, Deitke M, Kembhavi A, et al.[[page]](http://openaccess.thecvf.com/content/CVPR2021/html/Weihs_Visual_Room_Rearrangement_CVPR_2021_paper.html)
- [148]**Rearrangement: A challenge for embodied AI**. arXiv preprint arXiv:2011.01975, 2020.Batra D, Chang A X, Chernova S, et al.[[page]](https://arxiv.org/abs/2011.01975)
- [149]**Igibson 1.0: A simulation environment for interactive tasks in large realistic scenes**. In: Proceeding of the International Conference on Intelligent Robots and Systems, 2021: 7520-7527.Shen B, Xia F, Li C, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/9636667/)
- [150]**Igibson 2.0: Objectcentric simulation for robot learning of everyday household tasks**. arXiv preprint arXiv:2108.03272, 2021.Li C, Xia F, Mart√≠n-Mart√≠n R, et al.[[page]](https://arxiv.org/abs/2108.03272)
- [151]**Habitat: A platform for embodied AI research**. In: Proceeding of the IEEE/CVF International Conference on Computer Vision, 2019: 9339-9347.Savva M, Kadian A, Maksymets O, et al.[[page]](http://openaccess.thecvf.com/content_ICCV_2019/html/Savva_Habitat_A_Platform_for_Embodied_AI_Research_ICCV_2019_paper.html)
- [152]**Habitat-matterport 3D dataset (HM3D): 1000 large-scale 3D environments for embodied AI**. arXiv preprint arXiv:2109.08238, 2021.Ramakrishnan S K, Gokaslan A, Wijmans E, et al.[[page]](https://arxiv.org/abs/2109.08238)
- [153]**Multion: Benchmarking semantic map memory using multi-object navigation**. Advances in Neural Information Processing Systems, 2020, 33: 9700-9712.Wani S, Patel S, Jain U, et al.[[page]](https://proceedings.neurips.cc/paper/2020/hash/6e01383fd96a17ae51cc3e15447e7533-Abstract.html)
- [154]**Behavior-1k: A benchmark for embodied AI with 1,000 everyday activities and realistic simulation**. In: Proceeding of the Conference on Robot Learning, 2023: 80-93.Li C, Zhang R, Wong J, et al.[[page]](https://proceedings.mlr.press/v205/li23a.html)
- [155]**Behavior: Benchmark for everyday household activities in virtual, interactive, and ecological environments**. In: Proceeding of the Conference on Robot Learning, 2022: 477-490.Srivastava S, Li C, Lingelbach M, et al. [[page]](https://proceedings.mlr.press/v164/srivastava22a.html)
- [156]**Ai2-thor: An interactive 3d environment for visual AI**. arXiv preprint arXiv:1712.05474, 2017.Kolve E, Mottaghi R, Han W, et al. [[page]](https://arxiv.org/abs/1712.05474)
- [157]**Threedworld: A platform for interactive multi-modal physical simulation**. arXiv preprint arXiv:2007.04954, 2020.Gan C, Schwartz J, Alter S, et al.[[page]](https://arxiv.org/abs/2007.04954)
- [158]**The threedworld transport challenge: A visually guided task-and-motion planning benchmark towards physically realistic embodied AI**. In: Proceeding of the 2022 International Conference on Robotics and Automation, 2022: 8847-8854.Gan C, Zhou S, Schwartz J, et al. [[page]](https://arxiv.org/abs/2103.14025)
- [159]**Habitat 2.0: Training home assistants to rearrange their habitat**. Advances in Neural Information Processing Systems, 2021, 34: 251-266.Szot A, Clegg A, Undersander E, et al. [[page]](https://proceedings.neurips.cc/paper/2021/hash/021bbc7ee20b71134d53e20206bd6feb-Abstract.html)
## ÂÖ∑Ë∫´Â≠¶‰π†‰∏éËøõÂåñ [üîù](#-table-of-contents)
### Âü∫Á°ÄÊ®°Âûã

- [6]**The journey/DAO/TAO of embodied intelligence: From large models to foundation intelligence and parallel intelligence**. IEEE/CAA Journal of Automatica Sinica, 2024, 11(6): 1313-1316.Shen T, Sun J, Kong S, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/10539310/)
- [9]**LM-Nav: Robotic navigation with large pre-trained models of language, vision, and action**. In: Proceeding of the Conference on Robot Learning, 2023: 492-504.Shah D, Osi≈Ñski B, Levine S.[[page]](https://proceedings.mlr.press/v205/shah23b.html)
- [111]**Voxposer: Composable 3D value maps for robotic manipulation with language models**. arXiv preprint arXiv:2307.05973, 2023.Huang W, Wang C, Zhang R, et al.[[page]](https://arxiv.org/abs/2307.05973)
- [160]**Accurate medium-range global weather forecasting with 3D neural networks**. Nature, 2023, 619(7970): 533-538.Bi K, Xie L, Zhang H, et al.[[page]](https://www.nature.com/articles/s41586-023-06185-3)
- [161]**The emergence of intelligent enterprises: From CPS to CPSS**. IEEE Intelligent Systems, 2010, 25(4): 85-88.Wang F Y. [[page]](https://ieeexplore.ieee.org/abstract/document/5552591/)
- [162]  **Cyber-physical-social systems: The state of the art and perspectives**. IEEE Transactions on Computational Social Systems, 2018, 5(3): 829-840.Zhang J J, Wang F Y, Wang X, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/8464032/)
### Â¢ûÈáèÂ≠¶‰π†

- [70]**Overcoming catastrophic forgetting in neural networks**. Proceedings of the National Academy of Sciences, 2017, 114(13): 3521-3526.Kirkpatrick J, Pascanu R, Rabinowitz N, et al.[[page]](https://www.pnas.org/doi/abs/10.1073/pnas.1611835114)
- [71]**Rotate your networks: Better weight consolidation and less catastrophic forgetting**. In: Proceeding of the International Conference on Pattern Recognition, 2018: 2262-2268.Liu X, Masana M, Herranz L, et al. [[page]](https://ieeexplore.ieee.org/abstract/document/8545895/)
- [72]**Re-evaluating continual learning scenarios: A categorization and case for strong baselines**. arXiv preprint arXiv:1810.12488, 2018.Hsu Y C, Liu Y C, Ramasamy A, et al.[[page]](https://arxiv.org/abs/1810.12488)
- [73]**Distilling the knowledge in a neural network**. arXiv preprint arXiv:1503.02531, 2015.Hinton G, Vinyals O, Dean J. [[page]](https://arxiv.org/abs/1503.02531)
- [74]**Learning a unified classifier incrementally via rebalancing**. In: Proceeding of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019: 831-839.Hou S, Pan X, Loy C C, et al.[[page]](http://openaccess.thecvf.com/content_CVPR_2019/html/Hou_Learning_a_Unified_Classifier_Incrementally_via_Rebalancing_CVPR_2019_paper.html)
- [75]**End-to-end incremental learning**. In: Proceeding of the European Conference on Computer Vision, 2018: 233-248.Castro F M, Mar√≠n-Jim√©nez M J, Guil N, et al.[[page]](http://openaccess.thecvf.com/content_ECCV_2018/html/Francisco_M._Castro_End-to-End_Incremental_Learning_ECCV_2018_paper.html)
- [76]**Class-incremental learning via deep model consolidation**. In: Proceeding of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2020: 1131-1140.Zhang J, Zhang J, Ghosh S, et al.[[page]](http://openaccess.thecvf.com/content_WACV_2020/html/Zhang_Class-incremental_Learning_via_Deep_Model_Consolidation_WACV_2020_paper.html)
- [77]**PODNet: Pooled outputs distillation for small-tasks incremental learning**. In: Proceeding of the European Conference on Computer Vision, 2020: 86-102.Douillard A, Cord M, Ollion C, et al.[[page]](https://link.springer.com/chapter/10.1007/978-3-030-58565-5_6)
- [78]**Á±ªÂà´Â¢ûÈáèÂ≠¶‰π†Á†îÁ©∂ËøõÂ±ïÂíåÊÄßËÉΩËØÑ‰ª∑**. Ëá™Âä®ÂåñÂ≠¶Êä•, 2023, 49(3): 635-660.Êú±È£û, Âº†ÁÖ¶Â∞ß, ÂàòÊàêÊûó. [[page]](http://www.aas.net.cn/article/doi/10.16383/j.aas.c220588)
- [79]**Topology-preserving classincremental learning**. In: Proceeding of the European Conference on Computer Vision, 2020: 254-270.Tao X, Chang X, Hong X, et al. [[page]](https://link.springer.com/chapter/10.1007/978-3-030-58529-7_16)
- [80]**Small-task incremental learning**. ArXiv abs/2004.13513 (2020): n. pag.Douillard A, Cord M, Ollion C, et al.
- [81]**Icarl: Incremetal classifier and representation learning**. In: Proceeding of the IEEE Conference on Computer Vision and Pattern Recognition, 2017: 2001-2010.Rebuffi S A, Kolesnikov A, Sperl G, et al.[[page]](http://openaccess.thecvf.com/content_cvpr_2017/html/Rebuffi_iCaRL_Incremental_Classifier_CVPR_2017_paper.html)
- [82]**Generative adversarial networks**. Communications of the ACM, 2020, 63(11): 139-144.Goodfellow I, Pouget-Abadie J, Mirza M, et al. [[page]](https://dl.acm.org/doi/abs/10.1145/3422622)
- [83]**Latent replay for real-time continual learning.** In: Proceeding of the International Conference on Intelligent Robots and Systems, 2020: 10203-10209.Pellegrini L, Graffieti G, Lomonaco V, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/9341460/)
- [84]**Large scale incremental learning**. In: Proceeding of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019: 374-382.Wu Y, Chen Y, Wang L, et al.[[page]](http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Large_Scale_Incremental_Learning_CVPR_2019_paper.html)
- [85]**Overcoming catastrophic forgetting with hard attention to the task**. In: Proceeding of the International Conference on Machine Learning, 2018: 4548- 4557.[[page]](https://proceedings.mlr.press/v80/serra18a)
- [86]**Self-sustaining representation expansion for non-exemplar class-incremental learning**. In: Proceeding of the IEEE/CVF Conference on Computer Vision and Pattern RecognitionÔºå2022: 9296-9305.Zhu K, Zhai W, Cao Y, et al.[[page]](http://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Self-Sustaining_Representation_Expansion_for_Non-Exemplar_Class-Incremental_Learning_CVPR_2022_paper.html)
### Âº∫ÂåñÂ≠¶‰π†

- [87]**An overview of reservoir computing: Theory, applications and implementations**. In: Proceedings of the 15th European Symposium on Artificial Neural Networks, 2007: 471-482.Schrauwen B, Verstraeten D, Van Campenhout J.[[page]](https://biblio.ugent.be/publication/416607/file/447949)
- [88]**The role of feedback in morphological computation with compliant bodies**. Biological Cybernetics, 2012, 106: 595-613.Hauser H, Ijspeert A J, F√ºchslin R M, et al. [[page]](https://link.springer.com/article/10.1007/s00422-012-0516-4)
- [89]**Design and control of compliant tensegrity robots through simulation and hardware validation**. Journal of the Royal Society Interface, 2014, 11(98): 20140520.Caluwaerts K, Despraz J, I≈ü√ßen A, et al.[[page]](https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2014.0520)
- [90]**Developing an embodied gait on a compliant quadrupedal robot**. In: Proceeding of the International Conference on Intelligent Robots and Systems, 2015: 4486-4491.Degrave J, Caluwaerts K, Dambre J, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/7354014/)
- [91]**Stochastic optimal control methods for investigating the power of morphological computation**. Artificial Life, 2013, 19(1): 115-131.R√ºckert E A, Neumann G. [[page]](https://direct.mit.edu/artl/article-abstract/19/1/115/2735)
- [92]**Algorithmic design for embodied intelligence in synthetic cells**. IEEE Transactions on Automation Science and Engineering, 2020, 18(3): 864-875.Pervan A, Murphey T D.[[page]](https://ieeexplore.ieee.org/abstract/document/9305943/)
- [93]**Target-driven visual navigation in indoor scenes using deep reinforcement learning**. In: Proceeding of the 2017 IEEE International Conference on Robotics and Automation, 2017: 3357-3364.Zhu Y, Mottaghi R, Kolve E, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/7989381/)
- [94]**Hardware conditioned policies for multi-robot transfer learning**. Advances in Neural Information Processing Systems, 2018, 31.Chen T, Murali A, Gupta A. [[page]](https://proceedings.neurips.cc/paper/2018/hash/b8cfbf77a3d250a4523ba67a65a7d031-Abstract.html)
- [95]**Nervenet: Learning structured policy with graph neural networks**. In: Proceeding of the International Conference on Learning Representations, 2018.Wang T, Liao R, Ba J, et al. [[page]](https://openreview.net/forum?id=S1sqHMZCb)
- [96]**Snowflake: Scaling GNNs to high-dimensional continuous control via parameter freezing**. Advances in Neural Information Processing Systems, 2021, 34: 23983-23992.Blake C, Kurin V, Igl M, et al. [[page]](https://proceedings.neurips.cc/paper/2021/hash/c952ce98517ac529c60744ac28364b03-Abstract.html)
- [97]**Learning to control self-assembling morphologies: A study of generalization via modularity**. Advances in Neural Information Processing Systems, 2019, 32.Pathak D, Lu C, Darrell T, et al.[[page]](https://proceedings.neurips.cc/paper/8501-learning-to-control-self-assembling-morphologies-a-study-of-generalization-via-modularity)
- [98]**Data-efficient co-adaptation of morphology and behaviour with deep reinforcement learning**. In: Proceeding of the Conference on Robot Learning, 2020: 854-869.Luck K S, Amor H B, Calandra R.[[page]](https://proceedings.mlr.press/v100/luck20a.html)
- [99]**Data-efficient co-adaptation of morphology and behaviour with deep reinforcement learning**. ArXiv abs/1911.06832 (2019): n. pag.Luck K S, Amor H B, Calandra R.[[page]](https://proceedings.mlr.press/v100/luck20a.html)
- [100]**Reinforcement learning for improving agent design.** Artificial Life, 2019, 25(4): 352-365.Ha D.[[page]](https://direct.mit.edu/artl/article-abstract/25/4/352/93262)
## Â§öÊô∫ËÉΩ‰ΩìÂçèÂêå [üîù](#-table-of-contents)

- [101]**Asynchronous methods for deep reinforcement learning**. In: Proceeding of the International Conference on Machine Learning, 2016: 1928-1937.Mnih V, Badia A P, Mirza M, et al.[[page]](https://proceedings.mlr.press/v48/mniha16.html?ref=.)
- [102]**A multi-objective deep reinforcement learning framework**. Engineering Applications of Artificial Intelligence, 2020, 96: 103915.Nguyen T T, Nguyen N D, Vamplew P, et al.[[page]](https://www.sciencedirect.com/science/article/pii/S0952197620302475)
- [103]**Learning from an automated training agent**. Adaptation and Learning in Multiagent Systems. Springer Verlag, 1996: 195.Clouse J A.[[page]](https://web.cs.umass.edu/publication/docs/1995/UM-CS-1995-108.pdf)
- [104]**Accelerating reinforcement learning through implicit imitation**. Journal of Artificial Intelligence Research, 2003, 19: 569-629.Price B, Boutilier C.[[page]](http://www.jair.org/index.php/jair/article/view/10348)
- [105]**Double Q-learning**. Advances in Neural Information Processing Systems, 2010, 23.Hasselt H. [[page]](https://proceedings.neurips.cc/paper/2010/hash/091d584fced301b442654dd8c23b3fc9-Abstract.html)
- [106]**Deep attention recurrent Q-network**. arXiv preprint arXiv:1512.01693, 2015.Sorokin I, Seleznev A, Pavlov M, et al. [[page]](https://arxiv.org/abs/1512.01693)
- [107]**Multiagent learning using a variable learning rate**. Artificial Intelligence, 2002, 136(2): 215-250.Bowling M, Veloso M.[[page]](https://www.sciencedirect.com/science/article/pii/S0004370202001212)
- [108]**An algorithm for distributed reinforcement learning in cooperative multi-agent systems**. In: Proceeding of the Seventeenth International Conference on Machine Learning, 2000: 535-542.Lauer M, Riedmiller M A. [[page]](https://dl.acm.org/doi/abs/10.5555/645529.658113)
- [109]**Multi-agent reinforcement learning in sequential social dilemmas**. arXiv preprint arXiv:1702.03037, 2017.Leibo J Z, Zambaldi V, Lanctot M, et al.[[page]](https://arxiv.org/abs/1702.03037)
## ÂÖ∑Ë∫´Êô∫ËÉΩÁ≥ªÁªü [üîù](#-table-of-contents)
### ÁßªÂä®Êú∫Âô®‰∫∫

- [110]**Robot operating system 2: Design, architecture, and uses in the wild**. Science Robotics, 2022, 7(66): eabm6074.Macenski S, Foote T, Gerkey B, et al.[[page]](https://www.science.org/doi/abs/10.1126/scirobotics.abm6074)
- [113]**Voxposer: Composable 3D value maps for robotic manipulation with language models**. arXiv preprint arXiv:2307.05973, 2023.Huang W, Wang C, Zhang R, et al.[[page]](https://arxiv.org/abs/2307.05973)
- [114]**Design-to-test approach for programmable controllers in safety-critical automation systems**. IEEE Transactions on Industrial Informatics, 2020, 16(10): 6499-6508.Ma C, Provost J.[[page]](https://ieeexplore.ieee.org/abstract/document/8964436/)
- [115]**Binocular vision-based poleshaped obstacle detection and ranging study**. Applied Sciences, 2023, 13(23): 12617.Cai L, Zhou C, Wang Y, et al.[[page]](https://www.mdpi.com/2076-3417/13/23/12617)
- [116]**Reimagining an autonomous vehicle**. arXiv preprint arXiv:2108.05805, 2021.Hawke J, Badrinarayanan V, Kendall A, et al.[[page]](https://arxiv.org/abs/2108.05805)
- [117]**Scalability in perception for autonomous driving: Waymo open dataset**. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020: 2446-2454.Sun P, Kretzschmar H, Dotiwalla X, et al.[[page]](http://openaccess.thecvf.com/content_CVPR_2020/html/Sun_Scalability_in_Perception_for_Autonomous_Driving_Waymo_Open_Dataset_CVPR_2020_paper.html)
- [118]**End-to-end autonomous driving: Challenges and frontiers**. arXiv preprint arXiv:2306.16927, 2023.Chen L, Wu P, Chitta K, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/10614862/)
- [119]**Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation**. arXiv preprint arXiv:2401.02117, 2024.Fu Z, Zhao T Z, Finn C.[[page]](https://arxiv.org/abs/2401.02117)
- [120]**Modelling time efficiency of cobot-supported kit preparation**. The International Journal of Advanced Manufacturing Technology, 2020, 106: 2227-2241.Fager P, Calzavara M, Sgarbossa F.[[page]](https://link.springer.com/article/10.1007/s00170-019-04679-x)
- [121]**Âü∫‰∫éÂÖ∑Ë∫´Êô∫ËÉΩÁöÑÁßªÂä®Êìç‰ΩúÊú∫Âô®‰∫∫Á≥ªÁªüÂèëÂ±ïÁ†îÁ©∂**. ‰∏≠ÂõΩÂ∑•Á®ãÁßëÂ≠¶, 2024, 26(01): 139-148.ÂÖ∞Ê≤£Âçú, ËµµÊñáÂçö, Êú±ÂáØ, Á≠â.[[page]](https://www.engineering.org.cn/ch/10.15302/J-SSCAE-2024.01.010)
- [122]**Agent as cerebrum, controller as cerebellum: Implementing an embodied lmm-based agent on drones**. arXiv preprint arXiv:2311.15033, 2023.Zhao H, Pan F, Ping H, et al.[[page]](https://arxiv.org/abs/2311.15033)
### ‰ªøÁîüÊú∫Âô®‰∫∫

- [123]**Integrated tracking control of an underwater bionic robot based on multimodal motions**. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2023, 54(3): 1599-1610.Wang J, Wu Z, Zhang Y, et al.[[page]](https://ieeexplore.ieee.org/abstract/document/10319426/)
- [124]**NeuroDog: Quadruped embodiment using neural networks**. InÔºöProceedings of the ACM on Computer Graphics and Interactive Techniques, 2023: 1-19.Egan D, Cosker D, McDonnell, R.[[page]](https://dl.acm.org/doi/abs/10.1145/3606936)
- [125]**Advancements in humanoid robots: A comprehensive review and future prospects**. IEEE/CAA Journal of Automatica Sinica, 2024, 11(2): 301-328.Tong Y, Liu H, Zhang Z.Tong Y, Liu H, Zhang Z.[[page]](https://ieeexplore.ieee.org/abstract/document/10415857/)
- [126]**Learning agile soccer skills for a bipedal robot with deep reinforcement learning**. Science Robotics, 2024, 9(89): eadi8022.Haarnoja T, Moran B, Lever G, et al. [[page]](https://www.science.org/doi/abs/10.1126/scirobotics.adi8022)
- [127]**Bringing robots home: The rise of AI robots in consumer electronics**. arXiv preprint arXiv:2403.14449, 2024.Dong H, Liu Y, Chu T, Saddik A E. [[page]](https://arxiv.org/abs/2403.14449)
- [128]**Predictive control of zero moment point for terrain robot kinematics**. Materials Today: Proceedings, 2023, 2023(80): 122-127.Haldar A I, Pagar N D. [[page]](https://www.sciencedirect.com/science/article/pii/S2214785322068067)
- [129]**A survey of brain-inspired intelligent robots: Integration of vision, decision, motion control, and musculoskeletal systems**. IEEE Transactions on Cybernetics, 2021, 52(10): 11267-11280.Qiao H, Chen J, Huang X.[[page]](https://ieeexplore.ieee.org/abstract/document/9418510/)
- [130]**Brain-inspired intelligent robotics: Theoretical analysis and systematic application**. Machine Intelligence Research, 2023, 20(1): 1-18.Qiao H, Wu Y X, Zhong S L, et al. [[page]](https://link.springer.com/article/10.1007/s11633-022-1390-8)
- [131]**Design of topology optimized compliant legs for bio-inspired quadruped robots**. Scientific Reports, 2023, 13(1): 4875.Sun Y, Zong C, Pancheri F, et al.[[page]](https://www.nature.com/articles/s41598-023-32106-5)
- [132]**A study on quadruped mobile robots**. Mechanism and Machine Theory, 2023, 190: 105448.Taheri H, Mozayani N.[[page]](https://www.sciencedirect.com/science/article/pii/S0094114X23002197)
- [133]**Skin barrier reinforcement effect assessment of a spot-on based on natural ingredients in a dog model of tape stripping**. Veterinary Sciences, 2023, 9(8): 390.Id√©e A, Mosca M, Pin D.[[page]](https://www.mdpi.com/2306-7381/9/8/390)
- [134]**Multi-expert learning of adaptive legged locomotion**. Science Robotics, 2020, 5(49): eabb2174.Yang C, Yuan K, Zhu Q, et al. [[page]](https://www.science.org/doi/abs/10.1126/scirobotics.abb2174)
- [135]**Sailing through point clouds: Safe navigation using point cloud based control barrier functions**. arXiv preprint arXiv:2403.18206, 2024.Dai B, Khorrambakht R, Krishnamurthy P, et al.[[page]](https://arxiv.org/abs/2403.18206)
- [136]**Modality plug-and-play: Elastic modality adaptation in multimodal llms for embodied AI**. arXiv preprint arXiv:2312.07886, 2023.Huang K, Yang B, Gao W.[[page]](https://arxiv.org/abs/2312.07886)
- [137]**Three-dimensional kinematic modeling of helix-forming lamina-emergent soft smart actuators based on electroactive polymers**. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2017, 47(9): 2562-2573.Mutlu R, Alici G, Li W.[[page]](https://ieeexplore.ieee.org/abstract/document/7414481/)
- [138]**Punyo-1: Soft tactile-sensing upper-body robot for large object manipulation and physical human interaction**. In: Proceedings of the 2022 IEEE 5th International Conference on Soft Robotics, 2022: 844-851.Goncalves A, Kuppuswamy N, Beaulieu A, et al. [[page]](https://ieeexplore.ieee.org/abstract/document/9762117/)
- [139]**Active entanglement enables stochastic, topological grasping**. Proceedings of the National Academy of Sciences, 2022, 119(42): e2209819119.Becker K, Teeple C, Charles N, et al. [[page]](https://www.pnas.org/doi/abs/10.1073/pnas.2209819119)
- [140]**Octopus-inspired sensorized soft arm for environmental interaction**. Science Robotics, 2023, 8(84): eadh7852.[[page]](https://www.science.org/doi/abs/10.1126/scirobotics.adh7852)
- [141]**A concise guide to modelling the physics of embodied intelligence in soft robotics**. Nature Reviews Physics, 2022, 4(9): 595-610.Mengaldo G, Renda F, Brunton S L, et al.[[page]](https://www.nature.com/articles/s42254-022-00481-z)
### Âπ≥Ë°åÊú∫Âô®‰∫∫

- [142]**Âπ≥Ë°åÊú∫Âô®‰∫∫‰∏éÂπ≥Ë°å Êó†‰∫∫Á≥ªÁªü: Ê°ÜÊû∂„ÄÅÁªìÊûÑ„ÄÅËøáÁ®ã„ÄÅÂπ≥Âè∞ÂèäÂÖ∂Â∫îÁî®**. Ëá™Âä®ÂåñÂ≠¶Êä•, 2017, 43(2): 161‚àí175.ÔºâÁôΩÂ§©Áøî, ÁéãÂ∏Ö, Ê≤àÈúá, Êõπ‰∏úÁíû, ÈÉëÂçóÂÆÅ, ÁéãÈ£ûË∑É.[[page]](http://www.aas.net.cn/fileZDHXB/journal/article/zdhxb/2017/2/PDF/zdhxb-43-2-161.pdf)
- [143]**Êú∫Âô®‰∫∫ÁöÑÊú™Êù•ÂèëÂ±ï: ‰ªéÂ∑•‰∏öËá™Âä®ÂåñÂà∞Áü•ËØÜËá™Âä®Âåñ**. ÁßëÊäÄÂØºÊä•, 2015, 33(21): 39‚àí44.ÁéãÈ£ûË∑É.[[page]](http://www.kjdb.org/CN/article/downloadArticleFile.do?attachType=PDF&id=13134)
- [144]**ËΩØ‰ª∂ÂÆö‰πâÁöÑÁ≥ªÁªü‰∏éÁü•ËØÜËá™Âä®Âåñ: ‰ªéÁâõÈ°øÂà∞ÈªòÈ°øÁöÑÂπ≥Ë°åÂçáÂçé**. Ëá™Âä®ÂåñÂ≠¶Êä•, 2015, 41(1): 1‚àí8.ÁéãÈ£ûË∑É.[[page]](http://www.aas.net.cn/cn/article/doi/10.16383/j.aas.2015.c000001?viewType=HTML)
### ÁâπÁßçÊú∫Âô®‰∫∫
 coming soon
## üì∞ Citation
Submission in progress
## üëè Acknowledgements
